# Idiosyncratic + vol-scaled + smoothed reversal
# Volume conditioned MVO backtest

import datetime as dt
from pathlib import Path

import polars as pl
import sf_quant.data as sfd
import sf_quant.performance as sfp
from dotenv import load_dotenv

from research.utils import run_backtest_parallel

# Load environment variables
load_dotenv()

# Parameters
start = dt.date(1996, 1, 1)
end = dt.date(2024, 12, 31)
price_filter = 5
signal_name = "barra_reversal_volume"
IC = 0.05
gamma = 130
n_cpus = 8
constraints = ["ZeroBeta", "ZeroInvestment"]
results_folder = Path("results/experiment_7")

# Get data
data = sfd.load_assets(
    start=start,
    end=end,
    columns=[
        "date",
        "barrid",
        "ticker",
        "price",
        "return",
        "specific_return",
        "specific_risk",
        "predicted_beta",
        "daily_volume",
    ],
    in_universe=True,
).with_columns(
    pl.col("return").truediv(100),
    pl.col("specific_return").truediv(100),
    pl.col("specific_risk").truediv(100),
)

# Compute signal
signals = data.sort("barrid", "date").with_columns(
    pl.col("specific_return")
    .ewm_mean(span=5, min_samples=5)
    .mul(-1)
    .shift(1)
    .over("barrid")
    .alias(signal_name)
)

# Filter universe
filtered = signals.filter(
    pl.col("price").shift(1).over("barrid").gt(price_filter),
    pl.col(signal_name).is_not_null(),
    pl.col("predicted_beta").is_not_null(),
    pl.col("specific_risk").is_not_null(),
)

# Compute cross sectional z-scores for signal
scores = filtered.select(
    "date",
    "barrid",
    "price",
    "predicted_beta",
    "specific_risk",
    "daily_volume",
    pl.col(signal_name)
    .sub(pl.col(signal_name).mean())
    .truediv(pl.col(signal_name).std())
    .over("date")
    .alias("score"),
)


volume_scores = (
    scores.sort(["barrid", "date"])
    .with_columns(dollar_volume=pl.col("daily_volume").mul(pl.col("price")).log1p())
    .with_columns(
        # Mean can be calculated on Day 1
        dollar_volume_mean=pl.col("dollar_volume")
        .rolling_mean(window_size=252, min_samples=1)
        .over("barrid"),
        # Std Dev requires min_samples=2.
        # It will still produce a null on Day 1.
        dollar_volume_std=pl.col("dollar_volume")
        .rolling_std(window_size=252, min_samples=2)
        .over("barrid"),
    )
    .with_columns(
        volume_score=(
            (pl.col("dollar_volume") - pl.col("dollar_volume_mean"))
            /
            # fill the Day 1 null std with 1.0 (or any non-zero) to avoid division by null
            pl.col("dollar_volume_std").fill_null(1.0).clip(lower_bound=0.0001)
        )
        .fill_null(0.0)  # Catch any remaining edge cases
        .alias("volume_score")
    )
)


# Compute alphas with conditional logic: Set alpha to 0 if reversal is high with strong volume
alphas = (
    volume_scores.with_columns(
        # grinold and kahn alpha
        gk_alpha=pl.col("score") * IC * pl.col("specific_risk")
    )
    .with_columns(
        # Set alpha to 0 if both score > 2 and volume_score > 2
        alpha=pl.when((pl.col("score") > 2.0) & (pl.col("volume_score") > 2.0))
        # alpha=pl.when(((pl.col("score") > 2.0) | (pl.col('score') < -2.0)) & (pl.col("volume_score") > 2.0)) # Andrew: I think this is the correct implementation
        .then(0.0)
        .otherwise(pl.col("gk_alpha"))
    )
    .select("date", "barrid", "alpha", "predicted_beta")
    .sort("date", "barrid")
)

# Get forward returns
forward_returns = (
    data.sort("date", "barrid")
    .select(
        "date", "barrid", pl.col("return").shift(-1).over("barrid").alias("fwd_return")
    )
    .drop_nulls("fwd_return")
)

# Merge alphas and forward returns
merged = alphas.join(other=forward_returns, on=["date", "barrid"], how="inner")

# Get merged alphas and forward returns (inner join)
merged_alphas = merged.select("date", "barrid", "alpha")
merged_forward_returns = merged.select("date", "barrid", "fwd_return")

# Get ics
ics = sfp.generate_alpha_ics(
    alphas=alphas, rets=forward_returns, method="rank", window=22
)

# Save ic chart
rank_chart_path = results_folder / "rank_ic_chart.png"
pearson_chart_path = results_folder / "pearson_ic_chart.png"
sfp.generate_ic_chart(
    ics=ics,
    title="Barra Reversal Cumulative IC",
    ic_type="Rank",
    file_name=rank_chart_path,
)
sfp.generate_ic_chart(
    ics=ics,
    title="Barra Reversal Cumulative IC",
    ic_type="Pearson",
    file_name=pearson_chart_path,
)


# Run parallelized backtest
run_backtest_parallel(
    data=alphas,
    signal_name=signal_name,
    constraints=constraints,
    gamma=gamma,
    n_cpus=n_cpus,
)
